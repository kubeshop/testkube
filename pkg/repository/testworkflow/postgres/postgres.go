// Code generated by AI Assistant

package postgres

import (
	"context"
	"encoding/json"
	"errors"
	"fmt"
	"math"
	"time"

	"github.com/jackc/pgx/v5"
	"github.com/jackc/pgx/v5/pgtype"
	"github.com/jackc/pgx/v5/pgxpool"

	"github.com/kubeshop/testkube/pkg/api/v1/testkube"
	"github.com/kubeshop/testkube/pkg/database/postgres/sqlc"
	"github.com/kubeshop/testkube/pkg/repository/common"
	"github.com/kubeshop/testkube/pkg/repository/sequence"
	sequencepostgres "github.com/kubeshop/testkube/pkg/repository/sequence/postgres"
	"github.com/kubeshop/testkube/pkg/repository/testworkflow"
)

var _ testworkflow.Repository = (*PostgresRepository)(nil)

const (
	configParamSizeLimit = 100
)

type PostgresRepository struct {
	db                 sqlc.DatabaseInterface
	queries            sqlc.TestWorkflowExecutionQueriesInterface
	sequenceRepository sequence.Repository
}

type PostgresRepositoryOpt func(*PostgresRepository)

func NewPostgresRepository(db *pgxpool.Pool, opts ...PostgresRepositoryOpt) *PostgresRepository {
	r := &PostgresRepository{
		db:                 &sqlc.PgxPoolWrapper{Pool: db},
		queries:            sqlc.NewSQLCTestWorkflowExecutionQueriesWrapper(sqlc.New(db)),
		sequenceRepository: sequencepostgres.NewPostgresRepository(db),
	}

	for _, opt := range opts {
		opt(r)
	}

	return r
}

// WithQueriesInterface allows injecting a custom queries interface (useful for testing)
func WithQueriesInterface(queries sqlc.TestWorkflowExecutionQueriesInterface) PostgresRepositoryOpt {
	return func(r *PostgresRepository) {
		r.queries = queries
	}
}

// WithDatabaseInterface allows injecting a custom database interface (useful for testing)
func WithDatabaseInterface(db sqlc.DatabaseInterface) PostgresRepositoryOpt {
	return func(r *PostgresRepository) {
		r.db = db
	}
}

// Helper functions for type conversions
func toPgText(s string) pgtype.Text {
	if s == "" {
		return pgtype.Text{Valid: false}
	}
	return pgtype.Text{String: s, Valid: true}
}

func toPgBool(b bool) pgtype.Bool {
	return pgtype.Bool{Bool: b, Valid: true}
}

func toPgInt4(i int32) pgtype.Int4 {
	return pgtype.Int4{Int32: i, Valid: true}
}

func toPgTimestamp(t time.Time) pgtype.Timestamptz {
	if t.IsZero() {
		return pgtype.Timestamptz{Valid: false}
	}
	return pgtype.Timestamptz{Time: t, Valid: true}
}

func toJSONB(v interface{}) ([]byte, error) {
	if v == nil {
		return nil, nil
	}
	return json.Marshal(v)
}

func fromPgText(t pgtype.Text) string {
	if !t.Valid {
		return ""
	}
	return t.String
}

func fromPgBool(b pgtype.Bool) bool {
	if !b.Valid {
		return false
	}
	return b.Bool
}

func fromPgInt4(i pgtype.Int4) int32 {
	if !i.Valid {
		return 0
	}
	return i.Int32
}

func fromPgTimestamp(t pgtype.Timestamptz) time.Time {
	if !t.Valid {
		return time.Time{}
	}
	return t.Time
}

func fromJSONB[T any](data []byte) (*T, error) {
	if len(data) == 0 {
		return nil, nil
	}
	var result T
	err := json.Unmarshal(data, &result)
	if err != nil {
		return nil, err
	}
	return &result, nil
}

// Get method to use complete data
func (r *PostgresRepository) Get(ctx context.Context, id string) (testkube.TestWorkflowExecution, error) {
	tx, err := r.db.Begin(ctx)
	if err != nil {
		return testkube.TestWorkflowExecution{}, err
	}
	defer tx.Rollback(ctx)

	qtx := r.queries.WithTx(tx)

	// Get main execution data with all fields
	row, err := qtx.GetTestWorkflowExecution(ctx, id)
	if err != nil {
		if errors.Is(err, pgx.ErrNoRows) {
			return testkube.TestWorkflowExecution{}, fmt.Errorf("execution not found")
		}
		return testkube.TestWorkflowExecution{}, err
	}

	// Build the complete execution object from the row
	execution := r.convertCompleteRowToExecution(row)

	// Get signatures and build the tree structure
	signatures, err := qtx.GetTestWorkflowSignatures(ctx, execution.Id)
	if err != nil && !errors.Is(err, pgx.ErrNoRows) {
		return testkube.TestWorkflowExecution{}, err
	}
	execution.Signature = r.buildSignatureTree(signatures)

	// Get outputs
	outputs, err := qtx.GetTestWorkflowOutputs(ctx, execution.Id)
	if err != nil && !errors.Is(err, pgx.ErrNoRows) {
		return testkube.TestWorkflowExecution{}, err
	}
	execution.Output = r.convertOutputs(outputs)

	// Get reports
	reports, err := qtx.GetTestWorkflowReports(ctx, execution.Id)
	if err != nil && !errors.Is(err, pgx.ErrNoRows) {
		return testkube.TestWorkflowExecution{}, err
	}
	execution.Reports = r.convertReports(reports)

	// Get resource aggregations
	resourceAgg, err := qtx.GetTestWorkflowResourceAggregations(ctx, execution.Id)
	if err != nil && !errors.Is(err, pgx.ErrNoRows) {
		return testkube.TestWorkflowExecution{}, err
	} else if err == nil {
		execution.ResourceAggregations, err = r.convertResourceAggregations(resourceAgg)
		if err != nil {
			return testkube.TestWorkflowExecution{}, err
		}
	}

	if err = tx.Commit(ctx); err != nil {
		return testkube.TestWorkflowExecution{}, err
	}

	// Populate config params if resolved workflow exists
	if execution.ResolvedWorkflow != nil && execution.ResolvedWorkflow.Spec != nil {
		execution.ConfigParams = populateConfigParams(execution.ResolvedWorkflow, execution.ConfigParams)
	}

	return *execution.UnscapeDots(), nil
}

// Updated convertCompleteRowToExecution method to handle GetTestWorkflowExecutionRow
func (r *PostgresRepository) convertCompleteRowToExecution(row interface{}) *testkube.TestWorkflowExecution {
	execution := &testkube.TestWorkflowExecution{}

	switch v := row.(type) {
	case sqlc.GetTestWorkflowExecutionRow:
		r.populateExecutionFromCompleteRow(
			execution,
			v.ID, v.GroupID, v.RunnerID, v.RunnerTarget, v.RunnerOriginalTarget,
			v.Name, v.Namespace, v.Number, v.ScheduledAt, v.AssignedAt, v.StatusAt,
			v.TestWorkflowExecutionName, v.DisableWebhooks, v.Tags, v.RunningContext,
			v.ConfigParams, v.CreatedAt, v.UpdatedAt, v.Status, v.PredictedStatus,
			v.QueuedAt, v.StartedAt, v.FinishedAt, v.Duration, v.TotalDuration,
			v.DurationMs, v.PausedMs, v.TotalDurationMs, v.Pauses, v.Initialization,
			v.Steps, v.WorkflowName, v.WorkflowNamespace, v.WorkflowDescription,
			v.WorkflowLabels, v.WorkflowAnnotations, v.WorkflowCreated, v.WorkflowUpdated,
			v.WorkflowSpec, v.WorkflowReadOnly, v.WorkflowStatus, v.ResolvedWorkflowName,
			v.ResolvedWorkflowNamespace, v.ResolvedWorkflowDescription, v.ResolvedWorkflowLabels,
			v.ResolvedWorkflowAnnotations, v.ResolvedWorkflowCreated, v.ResolvedWorkflowUpdated,
			v.ResolvedWorkflowSpec, v.ResolvedWorkflowReadOnly, v.ResolvedWorkflowStatus,
		)
	case sqlc.GetTestWorkflowExecutionByNameAndTestWorkflowRow:
		r.populateExecutionFromCompleteRow(
			execution,
			v.ID, v.GroupID, v.RunnerID, v.RunnerTarget, v.RunnerOriginalTarget,
			v.Name, v.Namespace, v.Number, v.ScheduledAt, v.AssignedAt, v.StatusAt,
			v.TestWorkflowExecutionName, v.DisableWebhooks, v.Tags, v.RunningContext,
			v.ConfigParams, v.CreatedAt, v.UpdatedAt, v.Status, v.PredictedStatus,
			v.QueuedAt, v.StartedAt, v.FinishedAt, v.Duration, v.TotalDuration,
			v.DurationMs, v.PausedMs, v.TotalDurationMs, v.Pauses, v.Initialization,
			v.Steps, v.WorkflowName, v.WorkflowNamespace, v.WorkflowDescription,
			v.WorkflowLabels, v.WorkflowAnnotations, v.WorkflowCreated, v.WorkflowUpdated,
			v.WorkflowSpec, v.WorkflowReadOnly, v.WorkflowStatus, v.ResolvedWorkflowName,
			v.ResolvedWorkflowNamespace, v.ResolvedWorkflowDescription, v.ResolvedWorkflowLabels,
			v.ResolvedWorkflowAnnotations, v.ResolvedWorkflowCreated, v.ResolvedWorkflowUpdated,
			v.ResolvedWorkflowSpec, v.ResolvedWorkflowReadOnly, v.ResolvedWorkflowStatus,
		)
	case sqlc.GetLatestTestWorkflowExecutionByTestWorkflowRow:
		r.populateExecutionFromCompleteRow(
			execution,
			v.ID, v.GroupID, v.RunnerID, v.RunnerTarget, v.RunnerOriginalTarget,
			v.Name, v.Namespace, v.Number, v.ScheduledAt, v.AssignedAt, v.StatusAt,
			v.TestWorkflowExecutionName, v.DisableWebhooks, v.Tags, v.RunningContext,
			v.ConfigParams, v.CreatedAt, v.UpdatedAt, v.Status, v.PredictedStatus,
			v.QueuedAt, v.StartedAt, v.FinishedAt, v.Duration, v.TotalDuration,
			v.DurationMs, v.PausedMs, v.TotalDurationMs, v.Pauses, v.Initialization,
			v.Steps, v.WorkflowName, v.WorkflowNamespace, v.WorkflowDescription,
			v.WorkflowLabels, v.WorkflowAnnotations, v.WorkflowCreated, v.WorkflowUpdated,
			v.WorkflowSpec, v.WorkflowReadOnly, v.WorkflowStatus, v.ResolvedWorkflowName,
			v.ResolvedWorkflowNamespace, v.ResolvedWorkflowDescription, v.ResolvedWorkflowLabels,
			v.ResolvedWorkflowAnnotations, v.ResolvedWorkflowCreated, v.ResolvedWorkflowUpdated,
			v.ResolvedWorkflowSpec, v.ResolvedWorkflowReadOnly, v.ResolvedWorkflowStatus,
		)
	case sqlc.GetLatestTestWorkflowExecutionsByTestWorkflowsRow:
		r.populateExecutionFromCompleteRow(
			execution,
			v.ID, v.GroupID, v.RunnerID, v.RunnerTarget, v.RunnerOriginalTarget,
			v.Name, v.Namespace, v.Number, v.ScheduledAt, v.AssignedAt, v.StatusAt,
			v.TestWorkflowExecutionName, v.DisableWebhooks, v.Tags, v.RunningContext,
			v.ConfigParams, v.CreatedAt, v.UpdatedAt, v.Status, v.PredictedStatus,
			v.QueuedAt, v.StartedAt, v.FinishedAt, v.Duration, v.TotalDuration,
			v.DurationMs, v.PausedMs, v.TotalDurationMs, v.Pauses, v.Initialization,
			v.Steps, v.WorkflowName, v.WorkflowNamespace, v.WorkflowDescription,
			v.WorkflowLabels, v.WorkflowAnnotations, v.WorkflowCreated, v.WorkflowUpdated,
			v.WorkflowSpec, v.WorkflowReadOnly, v.WorkflowStatus, v.ResolvedWorkflowName,
			v.ResolvedWorkflowNamespace, v.ResolvedWorkflowDescription, v.ResolvedWorkflowLabels,
			v.ResolvedWorkflowAnnotations, v.ResolvedWorkflowCreated, v.ResolvedWorkflowUpdated,
			v.ResolvedWorkflowSpec, v.ResolvedWorkflowReadOnly, v.ResolvedWorkflowStatus,
		)
	case sqlc.GetRunningTestWorkflowExecutionsRow:
		r.populateExecutionFromCompleteRow(
			execution,
			v.ID, v.GroupID, v.RunnerID, v.RunnerTarget, v.RunnerOriginalTarget,
			v.Name, v.Namespace, v.Number, v.ScheduledAt, v.AssignedAt, v.StatusAt,
			v.TestWorkflowExecutionName, v.DisableWebhooks, v.Tags, v.RunningContext,
			v.ConfigParams, v.CreatedAt, v.UpdatedAt, v.Status, v.PredictedStatus,
			v.QueuedAt, v.StartedAt, v.FinishedAt, v.Duration, v.TotalDuration,
			v.DurationMs, v.PausedMs, v.TotalDurationMs, v.Pauses, v.Initialization,
			v.Steps, v.WorkflowName, v.WorkflowNamespace, v.WorkflowDescription,
			v.WorkflowLabels, v.WorkflowAnnotations, v.WorkflowCreated, v.WorkflowUpdated,
			v.WorkflowSpec, v.WorkflowReadOnly, v.WorkflowStatus, v.ResolvedWorkflowName,
			v.ResolvedWorkflowNamespace, v.ResolvedWorkflowDescription, v.ResolvedWorkflowLabels,
			v.ResolvedWorkflowAnnotations, v.ResolvedWorkflowCreated, v.ResolvedWorkflowUpdated,
			v.ResolvedWorkflowSpec, v.ResolvedWorkflowReadOnly, v.ResolvedWorkflowStatus,
		)
	case sqlc.GetTestWorkflowExecutionsRow:
		r.populateExecutionFromCompleteRow(
			execution,
			v.ID, v.GroupID, v.RunnerID, v.RunnerTarget, v.RunnerOriginalTarget,
			v.Name, v.Namespace, v.Number, v.ScheduledAt, v.AssignedAt, v.StatusAt,
			v.TestWorkflowExecutionName, v.DisableWebhooks, v.Tags, v.RunningContext,
			v.ConfigParams, v.CreatedAt, v.UpdatedAt, v.Status, v.PredictedStatus,
			v.QueuedAt, v.StartedAt, v.FinishedAt, v.Duration, v.TotalDuration,
			v.DurationMs, v.PausedMs, v.TotalDurationMs, v.Pauses, v.Initialization,
			v.Steps, v.WorkflowName, v.WorkflowNamespace, v.WorkflowDescription,
			v.WorkflowLabels, v.WorkflowAnnotations, v.WorkflowCreated, v.WorkflowUpdated,
			v.WorkflowSpec, v.WorkflowReadOnly, v.WorkflowStatus, v.ResolvedWorkflowName,
			v.ResolvedWorkflowNamespace, v.ResolvedWorkflowDescription, v.ResolvedWorkflowLabels,
			v.ResolvedWorkflowAnnotations, v.ResolvedWorkflowCreated, v.ResolvedWorkflowUpdated,
			v.ResolvedWorkflowSpec, v.ResolvedWorkflowReadOnly, v.ResolvedWorkflowStatus,
		)
	case sqlc.GetFinishedTestWorkflowExecutionsRow:
		r.populateExecutionFromCompleteRow(
			execution,
			v.ID, v.GroupID, v.RunnerID, v.RunnerTarget, v.RunnerOriginalTarget,
			v.Name, v.Namespace, v.Number, v.ScheduledAt, v.AssignedAt, v.StatusAt,
			v.TestWorkflowExecutionName, v.DisableWebhooks, v.Tags, v.RunningContext,
			v.ConfigParams, v.CreatedAt, v.UpdatedAt, v.Status, v.PredictedStatus,
			v.QueuedAt, v.StartedAt, v.FinishedAt, v.Duration, v.TotalDuration,
			v.DurationMs, v.PausedMs, v.TotalDurationMs, v.Pauses, v.Initialization,
			v.Steps, v.WorkflowName, v.WorkflowNamespace, v.WorkflowDescription,
			v.WorkflowLabels, v.WorkflowAnnotations, v.WorkflowCreated, v.WorkflowUpdated,
			v.WorkflowSpec, v.WorkflowReadOnly, v.WorkflowStatus, v.ResolvedWorkflowName,
			v.ResolvedWorkflowNamespace, v.ResolvedWorkflowDescription, v.ResolvedWorkflowLabels,
			v.ResolvedWorkflowAnnotations, v.ResolvedWorkflowCreated, v.ResolvedWorkflowUpdated,
			v.ResolvedWorkflowSpec, v.ResolvedWorkflowReadOnly, v.ResolvedWorkflowStatus,
		)
	case sqlc.GetUnassignedTestWorkflowExecutionsRow:
		r.populateExecutionFromCompleteRow(
			execution,
			v.ID, v.GroupID, v.RunnerID, v.RunnerTarget, v.RunnerOriginalTarget,
			v.Name, v.Namespace, v.Number, v.ScheduledAt, v.AssignedAt, v.StatusAt,
			v.TestWorkflowExecutionName, v.DisableWebhooks, v.Tags, v.RunningContext,
			v.ConfigParams, v.CreatedAt, v.UpdatedAt, v.Status, v.PredictedStatus,
			v.QueuedAt, v.StartedAt, v.FinishedAt, v.Duration, v.TotalDuration,
			v.DurationMs, v.PausedMs, v.TotalDurationMs, v.Pauses, v.Initialization,
			v.Steps, v.WorkflowName, v.WorkflowNamespace, v.WorkflowDescription,
			v.WorkflowLabels, v.WorkflowAnnotations, v.WorkflowCreated, v.WorkflowUpdated,
			v.WorkflowSpec, v.WorkflowReadOnly, v.WorkflowStatus, v.ResolvedWorkflowName,
			v.ResolvedWorkflowNamespace, v.ResolvedWorkflowDescription, v.ResolvedWorkflowLabels,
			v.ResolvedWorkflowAnnotations, v.ResolvedWorkflowCreated, v.ResolvedWorkflowUpdated,
			v.ResolvedWorkflowSpec, v.ResolvedWorkflowReadOnly, v.ResolvedWorkflowStatus,
		)
	default:
		// Handle unknown type - this should not happen if all queries return the same structure
		return &testkube.TestWorkflowExecution{}
	}

	return execution
}

// populateExecutionFromCompleteRow remains the same as in the previous response
func (r *PostgresRepository) populateExecutionFromCompleteRow(
	execution *testkube.TestWorkflowExecution,
	id string, groupID pgtype.Text, runnerID pgtype.Text, runnerTarget []byte, runnerOriginalTarget []byte,
	name string, namespace pgtype.Text, number pgtype.Int4, scheduledAt pgtype.Timestamptz, assignedAt pgtype.Timestamptz,
	statusAt pgtype.Timestamptz, testWorkflowExecutionName pgtype.Text, disableWebhooks pgtype.Bool,
	tags []byte, runningContext []byte, configParams []byte, createdAt pgtype.Timestamptz, updatedAt pgtype.Timestamptz,
	status pgtype.Text, predictedStatus pgtype.Text, queuedAt pgtype.Timestamptz, startedAt pgtype.Timestamptz,
	finishedAt pgtype.Timestamptz, duration pgtype.Text, totalDuration pgtype.Text, durationMs pgtype.Int4,
	pausedMs pgtype.Int4, totalDurationMs pgtype.Int4, pauses []byte, initialization []byte, steps []byte,
	workflowName pgtype.Text, workflowNamespace pgtype.Text, workflowDescription pgtype.Text,
	workflowLabels []byte, workflowAnnotations []byte, workflowCreated pgtype.Timestamptz,
	workflowUpdated pgtype.Timestamptz, workflowSpec []byte, workflowReadOnly pgtype.Bool, workflowStatus []byte,
	resolvedWorkflowName pgtype.Text, resolvedWorkflowNamespace pgtype.Text, resolvedWorkflowDescription pgtype.Text,
	resolvedWorkflowLabels []byte, resolvedWorkflowAnnotations []byte, resolvedWorkflowCreated pgtype.Timestamptz,
	resolvedWorkflowUpdated pgtype.Timestamptz, resolvedWorkflowSpec []byte, resolvedWorkflowReadOnly pgtype.Bool,
	resolvedWorkflowStatus []byte,
) {
	// Basic execution fields
	execution.Id = id
	execution.GroupId = fromPgText(groupID)
	execution.RunnerId = fromPgText(runnerID)
	execution.Name = name
	execution.Namespace = fromPgText(namespace)
	execution.Number = fromPgInt4(number)
	execution.ScheduledAt = fromPgTimestamp(scheduledAt)
	execution.AssignedAt = fromPgTimestamp(assignedAt)
	execution.StatusAt = fromPgTimestamp(statusAt)
	execution.TestWorkflowExecutionName = fromPgText(testWorkflowExecutionName)
	execution.DisableWebhooks = fromPgBool(disableWebhooks)

	// Parse JSONB fields
	r.parseExecutionJSONFields(execution, runnerTarget, runnerOriginalTarget, tags, runningContext, configParams)

	// Build result if exists
	if status.Valid {
		execution.Result = r.buildResultFromRow(
			status, predictedStatus, queuedAt, startedAt, finishedAt,
			duration, totalDuration, durationMs, pausedMs, totalDurationMs,
			pauses, initialization, steps,
		)
	}

	// Build workflow if exists
	if workflowName.Valid {
		execution.Workflow = r.buildWorkflowFromRow(
			workflowName, workflowNamespace, workflowDescription,
			workflowLabels, workflowAnnotations, workflowCreated,
			workflowUpdated, workflowSpec, workflowReadOnly, workflowStatus,
		)
	}

	// Build resolved workflow if exists
	if resolvedWorkflowName.Valid {
		execution.ResolvedWorkflow = r.buildWorkflowFromRow(
			resolvedWorkflowName, resolvedWorkflowNamespace, resolvedWorkflowDescription,
			resolvedWorkflowLabels, resolvedWorkflowAnnotations, resolvedWorkflowCreated,
			resolvedWorkflowUpdated, resolvedWorkflowSpec, resolvedWorkflowReadOnly, resolvedWorkflowStatus,
		)
	}
}

// Updated converter methods - all now use the same complete field set
func (r *PostgresRepository) convertRowToExecution(row sqlc.GetTestWorkflowExecutionByNameAndTestWorkflowRow) *testkube.TestWorkflowExecution {
	return r.convertCompleteRowToExecution(row)
}

func (r *PostgresRepository) convertRowToExecutionSimple(row sqlc.GetLatestTestWorkflowExecutionByTestWorkflowRow) *testkube.TestWorkflowExecution {
	return r.convertCompleteRowToExecution(row)
}

func (r *PostgresRepository) convertRowToExecutionFromList(row sqlc.GetTestWorkflowExecutionsRow) testkube.TestWorkflowExecution {
	return *r.convertCompleteRowToExecution(row)
}

func (r *PostgresRepository) convertRowToExecutionSimpleFromRunning(row sqlc.GetRunningTestWorkflowExecutionsRow) testkube.TestWorkflowExecution {
	return *r.convertCompleteRowToExecution(row)
}

func (r *PostgresRepository) convertRowToExecutionFromFinished(row sqlc.GetFinishedTestWorkflowExecutionsRow) testkube.TestWorkflowExecution {
	return *r.convertCompleteRowToExecution(row)
}

func (r *PostgresRepository) convertUnassignedRowToExecution(row sqlc.GetUnassignedTestWorkflowExecutionsRow) testkube.TestWorkflowExecution {
	return *r.convertCompleteRowToExecution(row)
}

func (r *PostgresRepository) convertRowToExecutionSummary(row sqlc.GetLatestTestWorkflowExecutionsByTestWorkflowsRow) testkube.TestWorkflowExecutionSummary {
	// Convert complete execution to summary
	execution := r.convertCompleteRowToExecution(row)
	return r.executionToSummary(*execution)
}

// Helper to convert full execution to summary
func (r *PostgresRepository) executionToSummary(execution testkube.TestWorkflowExecution) testkube.TestWorkflowExecutionSummary {
	summary := testkube.TestWorkflowExecutionSummary{
		Id:                   execution.Id,
		GroupId:              execution.GroupId,
		RunnerId:             execution.RunnerId,
		Name:                 execution.Name,
		Number:               execution.Number,
		ScheduledAt:          execution.ScheduledAt,
		StatusAt:             execution.StatusAt,
		Result:               execution.Result,
		Workflow:             execution.Workflow,
		Tags:                 execution.Tags,
		RunningContext:       execution.RunningContext,
		ConfigParams:         execution.ConfigParams,
		Reports:              execution.Reports,
		ResourceAggregations: execution.ResourceAggregations,
	}
	return summary
}

// Get signatures
func (r *PostgresRepository) buildSignatureTree(signatures []sqlc.TestWorkflowSignature) []testkube.TestWorkflowSignature {
	if len(signatures) == 0 {
		return nil
	}

	// Convert to map for easier processing
	sigMap := make(map[int32]*testkube.TestWorkflowSignature)
	parentChildMap := make(map[int32][]int32)

	for _, sig := range signatures {
		twSig := &testkube.TestWorkflowSignature{
			Ref:      fromPgText(sig.Ref),
			Name:     fromPgText(sig.Name),
			Category: fromPgText(sig.Category),
			Optional: fromPgBool(sig.Optional),
			Negative: fromPgBool(sig.Negative),
		}
		sigMap[sig.ID] = twSig

		if sig.ParentID.Valid {
			parentChildMap[sig.ParentID.Int32] = append(parentChildMap[sig.ParentID.Int32], sig.ID)
		}
	}

	// Build tree structure
	var buildChildren func(parentId int32) []testkube.TestWorkflowSignature
	buildChildren = func(parentId int32) []testkube.TestWorkflowSignature {
		var children []testkube.TestWorkflowSignature
		for _, childId := range parentChildMap[parentId] {
			child := *sigMap[childId]
			child.Children = buildChildren(childId)
			children = append(children, child)
		}
		return children
	}

	// Find root signatures (those without parents)
	var roots []testkube.TestWorkflowSignature
	for _, sig := range signatures {
		if !sig.ParentID.Valid {
			root := *sigMap[sig.ID]
			root.Children = buildChildren(sig.ID)
			roots = append(roots, root)
		}
	}

	return roots
}

func (r *PostgresRepository) convertOutputs(outputs []sqlc.TestWorkflowOutput) []testkube.TestWorkflowOutput {
	result := make([]testkube.TestWorkflowOutput, len(outputs))
	for i, output := range outputs {
		result[i] = testkube.TestWorkflowOutput{
			Ref:  fromPgText(output.Ref),
			Name: fromPgText(output.Name),
		}
		if len(output.Value) > 0 {
			json.Unmarshal(output.Value, &result[i].Value)
		}
	}
	return result
}

func (r *PostgresRepository) convertReports(reports []sqlc.TestWorkflowReport) []testkube.TestWorkflowReport {
	result := make([]testkube.TestWorkflowReport, len(reports))
	for i, report := range reports {
		result[i] = testkube.TestWorkflowReport{
			Ref:  fromPgText(report.Ref),
			Kind: fromPgText(report.Kind),
			File: fromPgText(report.File),
		}
		if len(report.Summary) > 0 {
			summary, _ := fromJSONB[testkube.TestWorkflowReportSummary](report.Summary)
			result[i].Summary = summary
		}
	}
	return result
}

func (r *PostgresRepository) convertResourceAggregations(agg sqlc.TestWorkflowResourceAggregation) (*testkube.TestWorkflowExecutionResourceAggregationsReport, error) {
	result := &testkube.TestWorkflowExecutionResourceAggregationsReport{}

	if len(agg.Global) > 0 {
		err := json.Unmarshal(agg.Global, &result.Global)
		if err != nil {
			return nil, err
		}
	}

	if len(agg.Step) > 0 {
		err := json.Unmarshal(agg.Step, &result.Step)
		if err != nil {
			return nil, err
		}
	}

	return result, nil
}

// GetByNameAndTestWorkflow returns execution by name and workflow name
func (r *PostgresRepository) GetByNameAndTestWorkflow(ctx context.Context, name, workflowName string) (testkube.TestWorkflowExecution, error) {
	tx, err := r.db.Begin(ctx)
	if err != nil {
		return testkube.TestWorkflowExecution{}, err
	}
	defer tx.Rollback(ctx)

	qtx := r.queries.WithTx(tx)

	// Get main execution data with all fields
	row, err := qtx.GetTestWorkflowExecutionByNameAndTestWorkflow(ctx, sqlc.GetTestWorkflowExecutionByNameAndTestWorkflowParams{
		Name:         name,
		WorkflowName: toPgText(workflowName),
	})
	if err != nil {
		if errors.Is(err, pgx.ErrNoRows) {
			return testkube.TestWorkflowExecution{}, fmt.Errorf("execution not found")
		}
		return testkube.TestWorkflowExecution{}, err
	}

	// Build the complete execution object from the row
	execution := r.convertCompleteRowToExecution(row)

	// Get signatures and build the tree structure
	signatures, err := qtx.GetTestWorkflowSignatures(ctx, execution.Id)
	if err != nil && !errors.Is(err, pgx.ErrNoRows) {
		return testkube.TestWorkflowExecution{}, err
	}
	execution.Signature = r.buildSignatureTree(signatures)

	// Get outputs
	outputs, err := qtx.GetTestWorkflowOutputs(ctx, execution.Id)
	if err != nil && !errors.Is(err, pgx.ErrNoRows) {
		return testkube.TestWorkflowExecution{}, err
	}
	execution.Output = r.convertOutputs(outputs)

	// Get reports
	reports, err := qtx.GetTestWorkflowReports(ctx, execution.Id)
	if err != nil && !errors.Is(err, pgx.ErrNoRows) {
		return testkube.TestWorkflowExecution{}, err
	}
	execution.Reports = r.convertReports(reports)

	// Get resource aggregations
	resourceAgg, err := qtx.GetTestWorkflowResourceAggregations(ctx, execution.Id)
	if err != nil && !errors.Is(err, pgx.ErrNoRows) {
		return testkube.TestWorkflowExecution{}, err
	} else if err == nil {
		execution.ResourceAggregations, err = r.convertResourceAggregations(resourceAgg)
		if err != nil {
			return testkube.TestWorkflowExecution{}, err
		}
	}

	if err = tx.Commit(ctx); err != nil {
		return testkube.TestWorkflowExecution{}, err
	}

	// Populate config params if resolved workflow exists
	if execution.ResolvedWorkflow != nil && execution.ResolvedWorkflow.Spec != nil {
		execution.ConfigParams = populateConfigParams(execution.ResolvedWorkflow, execution.ConfigParams)
	}

	return *execution.UnscapeDots(), nil
}

// GetLatestByTestWorkflow returns latest execution for a workflow
func (r *PostgresRepository) GetLatestByTestWorkflow(ctx context.Context, workflowName string) (*testkube.TestWorkflowExecution, error) {
	tx, err := r.db.Begin(ctx)
	if err != nil {
		return nil, err
	}
	defer tx.Rollback(ctx)

	qtx := r.queries.WithTx(tx)

	// Get main execution data with all fields
	row, err := qtx.GetLatestTestWorkflowExecutionByTestWorkflow(ctx, workflowName)
	if err != nil {
		if errors.Is(err, pgx.ErrNoRows) {
			return nil, fmt.Errorf("execution not found")
		}
		return nil, err
	}

	// Build the complete execution object from the row
	execution := r.convertCompleteRowToExecution(row)

	// Get signatures and build the tree structure
	signatures, err := qtx.GetTestWorkflowSignatures(ctx, execution.Id)
	if err != nil && !errors.Is(err, pgx.ErrNoRows) {
		return nil, err
	}
	execution.Signature = r.buildSignatureTree(signatures)

	// Get outputs
	outputs, err := qtx.GetTestWorkflowOutputs(ctx, execution.Id)
	if err != nil && !errors.Is(err, pgx.ErrNoRows) {
		return nil, err
	}
	execution.Output = r.convertOutputs(outputs)

	// Get reports
	reports, err := qtx.GetTestWorkflowReports(ctx, execution.Id)
	if err != nil && !errors.Is(err, pgx.ErrNoRows) {
		return nil, err
	}
	execution.Reports = r.convertReports(reports)

	// Get resource aggregations
	resourceAgg, err := qtx.GetTestWorkflowResourceAggregations(ctx, execution.Id)
	if err != nil && !errors.Is(err, pgx.ErrNoRows) {
		return nil, err
	} else if err == nil {
		execution.ResourceAggregations, err = r.convertResourceAggregations(resourceAgg)
		if err != nil {
			return nil, err
		}
	}

	if err = tx.Commit(ctx); err != nil {
		return nil, err
	}

	// Populate config params if resolved workflow exists
	if execution.ResolvedWorkflow != nil && execution.ResolvedWorkflow.Spec != nil {
		execution.ConfigParams = populateConfigParams(execution.ResolvedWorkflow, execution.ConfigParams)
	}

	return execution.UnscapeDots(), nil
}

// GetLatestByTestWorkflows returns latest executions for multiple workflows
func (r *PostgresRepository) GetLatestByTestWorkflows(ctx context.Context, workflowNames []string) ([]testkube.TestWorkflowExecutionSummary, error) {
	if len(workflowNames) == 0 {
		return nil, nil
	}

	rows, err := r.queries.GetLatestTestWorkflowExecutionsByTestWorkflows(ctx, workflowNames)
	if err != nil {
		return nil, err
	}

	result := make([]testkube.TestWorkflowExecutionSummary, len(rows))
	for i, row := range rows {
		// Convert complete execution to summary
		execution := r.convertCompleteRowToExecution(row)
		result[i] = r.executionToSummary(*execution)
		result[i].UnscapeDots()

		// Populate config params if resolved workflow exists
		if execution.ResolvedWorkflow != nil && execution.ResolvedWorkflow.Spec != nil {
			result[i].ConfigParams = populateConfigParams(execution.ResolvedWorkflow, result[i].ConfigParams)
		}
	}

	return result, nil
}

// GetRunning returns running executions
func (r *PostgresRepository) GetRunning(ctx context.Context) ([]testkube.TestWorkflowExecution, error) {
	rows, err := r.queries.GetRunningTestWorkflowExecutions(ctx)
	if err != nil {
		return nil, err
	}

	result := make([]testkube.TestWorkflowExecution, len(rows))
	for i, row := range rows {
		execution := r.convertCompleteRowToExecution(row)
		result[i] = *execution.UnscapeDots()

		// Populate config params if resolved workflow exists
		if execution.ResolvedWorkflow != nil && execution.ResolvedWorkflow.Spec != nil {
			result[i].ConfigParams = populateConfigParams(execution.ResolvedWorkflow, result[i].ConfigParams)
		}
	}

	return result, nil
}

// GetFinished returns finished executions with filter
func (r *PostgresRepository) GetFinished(ctx context.Context, filter testworkflow.Filter) ([]testkube.TestWorkflowExecution, error) {
	params := r.buildFinishedExecutionParams(filter)
	rows, err := r.queries.GetFinishedTestWorkflowExecutions(ctx, params)
	if err != nil {
		return nil, err
	}

	result := make([]testkube.TestWorkflowExecution, len(rows))
	for i, row := range rows {
		execution := r.convertCompleteRowToExecution(row)
		result[i] = *execution.UnscapeDots()

		// Populate config params if resolved workflow exists
		if execution.ResolvedWorkflow != nil && execution.ResolvedWorkflow.Spec != nil {
			result[i].ConfigParams = populateConfigParams(execution.ResolvedWorkflow, result[i].ConfigParams)
		}
	}

	return result, nil
}

// GetExecutionsTotals returns execution totals with filter
func (r *PostgresRepository) GetExecutionsTotals(ctx context.Context, filter ...testworkflow.Filter) (testkube.ExecutionsTotals, error) {
	var params sqlc.GetTestWorkflowExecutionsTotalsParams
	if len(filter) > 0 {
		params = r.buildTotalsParams(filter[0])
	}

	rows, err := r.queries.GetTestWorkflowExecutionsTotals(ctx, params)
	if err != nil {
		return testkube.ExecutionsTotals{}, err
	}

	totals := testkube.ExecutionsTotals{}
	var sum int32

	for _, row := range rows {
		count := int32(row.Count)
		sum += count

		if !row.Status.Valid {
			continue
		}

		switch testkube.TestWorkflowStatus(row.Status.String) {
		case testkube.QUEUED_TestWorkflowStatus:
			totals.Queued = count
		case testkube.RUNNING_TestWorkflowStatus:
			totals.Running = count
		case testkube.PASSED_TestWorkflowStatus:
			totals.Passed = count
		case testkube.FAILED_TestWorkflowStatus, testkube.ABORTED_TestWorkflowStatus:
			totals.Failed = count
		}
	}
	totals.Results = sum

	return totals, nil
}

// GetExecutions returns executions with filter
func (r *PostgresRepository) GetExecutions(ctx context.Context, filter testworkflow.Filter) ([]testkube.TestWorkflowExecution, error) {
	params := r.buildExecutionParams(filter)
	rows, err := r.queries.GetTestWorkflowExecutions(ctx, params)
	if err != nil {
		return nil, err
	}

	result := make([]testkube.TestWorkflowExecution, len(rows))
	for i, row := range rows {
		execution := r.convertCompleteRowToExecution(row)
		result[i] = *execution.UnscapeDots()

		// Populate config params if resolved workflow exists
		if execution.ResolvedWorkflow != nil && execution.ResolvedWorkflow.Spec != nil {
			result[i].ConfigParams = populateConfigParams(execution.ResolvedWorkflow, result[i].ConfigParams)
		}
	}

	return result, nil
}

// GetExecutionsSummary method
func (r *PostgresRepository) GetExecutionsSummary(ctx context.Context, filter testworkflow.Filter) ([]testkube.TestWorkflowExecutionSummary, error) {
	params := r.buildSummaryParams(filter)
	rows, err := r.queries.GetTestWorkflowExecutionsSummary(ctx, params)
	if err != nil {
		return nil, err
	}

	result := make([]testkube.TestWorkflowExecutionSummary, len(rows))
	for i, row := range rows {
		// Convert complete execution to summary
		execution := r.convertCompleteRowToExecution(row)
		result[i] = r.executionToSummary(*execution)
		result[i].UnscapeDots()

		// Populate config params if resolved workflow exists
		if execution.ResolvedWorkflow != nil && execution.ResolvedWorkflow.Spec != nil {
			result[i].ConfigParams = populateConfigParams(execution.ResolvedWorkflow, result[i].ConfigParams)
		}
	}

	return result, nil
}

// Insert inserts new execution
func (r *PostgresRepository) Insert(ctx context.Context, result testkube.TestWorkflowExecution) error {
	execution := result.Clone()
	execution.EscapeDots()

	if execution.Reports == nil {
		execution.Reports = []testkube.TestWorkflowReport{}
	}

	return r.insertExecutionWithTransaction(ctx, execution)
}

func (r *PostgresRepository) insertExecutionWithTransaction(ctx context.Context, execution *testkube.TestWorkflowExecution) error {
	tx, err := r.db.Begin(ctx)
	if err != nil {
		return err
	}
	defer tx.Rollback(ctx)

	qtx := r.queries.WithTx(tx)

	// Insert main execution
	err = r.insertMainExecution(ctx, qtx, execution)
	if err != nil {
		return err
	}

	// Insert related data
	if err = r.insertSignatures(ctx, qtx, execution.Id, execution.Signature, 0); err != nil {
		return err
	}

	if execution.Result != nil {
		if err = r.insertResult(ctx, qtx, execution.Id, execution.Result); err != nil {
			return err
		}
	}

	if err = r.insertOutputs(ctx, qtx, execution.Id, execution.Output); err != nil {
		return err
	}

	if err = r.insertReports(ctx, qtx, execution.Id, execution.Reports); err != nil {
		return err
	}

	if execution.ResourceAggregations != nil {
		if err = r.insertResourceAggregations(ctx, qtx, execution.Id, execution.ResourceAggregations); err != nil {
			return err
		}
	}

	if execution.Workflow != nil {
		if err = r.insertWorkflow(ctx, qtx, execution.Id, "workflow", execution.Workflow); err != nil {
			return err
		}
	}

	if execution.ResolvedWorkflow != nil {
		if err = r.insertWorkflow(ctx, qtx, execution.Id, "resolved_workflow", execution.ResolvedWorkflow); err != nil {
			return err
		}
	}

	return tx.Commit(ctx)
}

func (r *PostgresRepository) insertMainExecution(ctx context.Context, qtx sqlc.TestWorkflowExecutionQueriesInterface, execution *testkube.TestWorkflowExecution) error {
	runnerTarget, _ := toJSONB(execution.RunnerTarget)
	runnerOriginalTarget, _ := toJSONB(execution.RunnerOriginalTarget)
	tags, _ := toJSONB(execution.Tags)
	runningContext, _ := toJSONB(execution.RunningContext)
	configParams, _ := toJSONB(execution.ConfigParams)

	return qtx.InsertTestWorkflowExecution(ctx, sqlc.InsertTestWorkflowExecutionParams{
		ID:                        execution.Id,
		GroupID:                   toPgText(execution.GroupId),
		RunnerID:                  toPgText(execution.RunnerId),
		RunnerTarget:              runnerTarget,
		RunnerOriginalTarget:      runnerOriginalTarget,
		Name:                      execution.Name,
		Namespace:                 toPgText(execution.Namespace),
		Number:                    toPgInt4(execution.Number),
		ScheduledAt:               toPgTimestamp(execution.ScheduledAt),
		AssignedAt:                toPgTimestamp(execution.AssignedAt),
		StatusAt:                  toPgTimestamp(execution.StatusAt),
		TestWorkflowExecutionName: toPgText(execution.TestWorkflowExecutionName),
		DisableWebhooks:           toPgBool(execution.DisableWebhooks),
		Tags:                      tags,
		RunningContext:            runningContext,
		ConfigParams:              configParams,
	})
}

func (r *PostgresRepository) insertSignatures(ctx context.Context, qtx sqlc.TestWorkflowExecutionQueriesInterface, executionId string, signatures []testkube.TestWorkflowSignature, parentId int32) error {
	for _, sig := range signatures {
		var parentIdPg pgtype.Int4
		if parentId > 0 {
			parentIdPg = toPgInt4(parentId)
		}

		id, err := qtx.InsertTestWorkflowSignature(ctx, sqlc.InsertTestWorkflowSignatureParams{
			ExecutionID: executionId,
			Ref:         toPgText(sig.Ref),
			Name:        toPgText(sig.Name),
			Category:    toPgText(sig.Category),
			Optional:    toPgBool(sig.Optional),
			Negative:    toPgBool(sig.Negative),
			ParentID:    parentIdPg,
		})
		if err != nil {
			return err
		}

		//For children, we would need to get the inserted ID and use it as parentId
		// This requires modification to return the ID from the insert
		if len(sig.Children) > 0 {
			// TODO: Implement recursive insertion for children
			// This would require getting the ID of the just inserted signature
			if err = r.insertSignatures(ctx, qtx, executionId, sig.Children, id); err != nil {
				return err
			}
		}
	}
	return nil
}

func (r *PostgresRepository) insertResult(ctx context.Context, qtx sqlc.TestWorkflowExecutionQueriesInterface, executionId string, result *testkube.TestWorkflowResult) error {
	pauses, _ := toJSONB(result.Pauses)
	initialization, _ := toJSONB(result.Initialization)
	steps, _ := toJSONB(result.Steps)

	var status, predictedStatus pgtype.Text
	if result.Status != nil {
		status = toPgText(string(*result.Status))
	}
	if result.PredictedStatus != nil {
		predictedStatus = toPgText(string(*result.PredictedStatus))
	}

	return qtx.InsertTestWorkflowResult(ctx, sqlc.InsertTestWorkflowResultParams{
		ExecutionID:     executionId,
		Status:          status,
		PredictedStatus: predictedStatus,
		QueuedAt:        toPgTimestamp(result.QueuedAt),
		StartedAt:       toPgTimestamp(result.StartedAt),
		FinishedAt:      toPgTimestamp(result.FinishedAt),
		Duration:        toPgText(result.Duration),
		TotalDuration:   toPgText(result.TotalDuration),
		DurationMs:      toPgInt4(result.DurationMs),
		PausedMs:        toPgInt4(result.PausedMs),
		TotalDurationMs: toPgInt4(result.TotalDurationMs),
		Pauses:          pauses,
		Initialization:  initialization,
		Steps:           steps,
	})
}

func (r *PostgresRepository) insertOutputs(ctx context.Context, qtx sqlc.TestWorkflowExecutionQueriesInterface, executionId string, outputs []testkube.TestWorkflowOutput) error {
	for _, output := range outputs {
		value, _ := toJSONB(output.Value)
		err := qtx.InsertTestWorkflowOutput(ctx, sqlc.InsertTestWorkflowOutputParams{
			ExecutionID: executionId,
			Ref:         toPgText(output.Ref),
			Name:        toPgText(output.Name),
			Value:       value,
		})
		if err != nil {
			return err
		}
	}
	return nil
}

func (r *PostgresRepository) insertReports(ctx context.Context, qtx sqlc.TestWorkflowExecutionQueriesInterface, executionId string, reports []testkube.TestWorkflowReport) error {
	for _, report := range reports {
		summary, _ := toJSONB(report.Summary)
		err := qtx.InsertTestWorkflowReport(ctx, sqlc.InsertTestWorkflowReportParams{
			ExecutionID: executionId,
			Ref:         toPgText(report.Ref),
			Kind:        toPgText(report.Kind),
			File:        toPgText(report.File),
			Summary:     summary,
		})
		if err != nil {
			return err
		}
	}
	return nil
}

func (r *PostgresRepository) insertResourceAggregations(ctx context.Context, qtx sqlc.TestWorkflowExecutionQueriesInterface, executionId string, agg *testkube.TestWorkflowExecutionResourceAggregationsReport) error {
	global, _ := toJSONB(agg.Global)
	step, _ := toJSONB(agg.Step)

	return qtx.InsertTestWorkflowResourceAggregations(ctx, sqlc.InsertTestWorkflowResourceAggregationsParams{
		ExecutionID: executionId,
		Global:      global,
		Step:        step,
	})
}

func (r *PostgresRepository) insertWorkflow(ctx context.Context, qtx sqlc.TestWorkflowExecutionQueriesInterface, executionId, workflowType string, workflow *testkube.TestWorkflow) error {
	labels, _ := toJSONB(workflow.Labels)
	annotations, _ := toJSONB(workflow.Annotations)
	spec, _ := toJSONB(workflow.Spec)
	status, _ := toJSONB(workflow.Status)

	return qtx.InsertTestWorkflow(ctx, sqlc.InsertTestWorkflowParams{
		ExecutionID:  executionId,
		WorkflowType: workflowType,
		Name:         toPgText(workflow.Name),
		Namespace:    toPgText(workflow.Namespace),
		Description:  toPgText(workflow.Description),
		Labels:       labels,
		Annotations:  annotations,
		Created:      toPgTimestamp(workflow.Created),
		Updated:      toPgTimestamp(workflow.Updated),
		Spec:         spec,
		ReadOnly:     toPgBool(workflow.ReadOnly),
		Status:       status,
	})
}

// Update updates execution
func (r *PostgresRepository) Update(ctx context.Context, result testkube.TestWorkflowExecution) error {
	execution := result.Clone()
	execution.EscapeDots()

	if execution.Reports == nil {
		execution.Reports = []testkube.TestWorkflowReport{}
	}

	// For update, we need to delete and re-insert related data
	return r.updateExecutionWithTransaction(ctx, execution)
}

func (r *PostgresRepository) updateExecutionWithTransaction(ctx context.Context, execution *testkube.TestWorkflowExecution) error {
	tx, err := r.db.Begin(ctx)
	if err != nil {
		return err
	}
	defer tx.Rollback(ctx)

	qtx := r.queries.WithTx(tx)

	// Update main execution (we need to create this query)
	err = r.updateMainExecution(ctx, qtx, execution)
	if err != nil {
		return err
	}

	// Delete and re-insert related data
	// Delete existing signatures, outputs, reports
	// (These would need to be implemented as additional queries)

	// Re-insert all related data
	if err = r.insertSignatures(ctx, qtx, execution.Id, execution.Signature, 0); err != nil {
		return err
	}

	if execution.Result != nil {
		if err = r.insertResult(ctx, qtx, execution.Id, execution.Result); err != nil {
			return err
		}
	}

	if err = r.insertOutputs(ctx, qtx, execution.Id, execution.Output); err != nil {
		return err
	}

	if err = r.insertReports(ctx, qtx, execution.Id, execution.Reports); err != nil {
		return err
	}

	if execution.ResourceAggregations != nil {
		if err = r.insertResourceAggregations(ctx, qtx, execution.Id, execution.ResourceAggregations); err != nil {
			return err
		}
	}

	if execution.Workflow != nil {
		if err = r.insertWorkflow(ctx, qtx, execution.Id, "workflow", execution.Workflow); err != nil {
			return err
		}
	}

	if execution.ResolvedWorkflow != nil {
		if err = r.insertWorkflow(ctx, qtx, execution.Id, "resolved_workflow", execution.ResolvedWorkflow); err != nil {
			return err
		}
	}

	return tx.Commit(ctx)
}

// UpdateResult updates only the result
func (r *PostgresRepository) UpdateResult(ctx context.Context, id string, result *testkube.TestWorkflowResult) error {
	pauses, _ := toJSONB(result.Pauses)
	initialization, _ := toJSONB(result.Initialization)
	steps, _ := toJSONB(result.Steps)

	var status, predictedStatus pgtype.Text
	if result.Status != nil {
		status = toPgText(string(*result.Status))
	}
	if result.PredictedStatus != nil {
		predictedStatus = toPgText(string(*result.PredictedStatus))
	}

	err := r.queries.UpdateTestWorkflowExecutionResult(ctx, sqlc.UpdateTestWorkflowExecutionResultParams{
		ExecutionID:     id,
		Status:          status,
		PredictedStatus: predictedStatus,
		QueuedAt:        toPgTimestamp(result.QueuedAt),
		StartedAt:       toPgTimestamp(result.StartedAt),
		FinishedAt:      toPgTimestamp(result.FinishedAt),
		Duration:        toPgText(result.Duration),
		TotalDuration:   toPgText(result.TotalDuration),
		DurationMs:      toPgInt4(result.DurationMs),
		PausedMs:        toPgInt4(result.PausedMs),
		TotalDurationMs: toPgInt4(result.TotalDurationMs),
		Pauses:          pauses,
		Initialization:  initialization,
		Steps:           steps,
	})
	if err != nil {
		return err
	}

	// Update status_at if result has finished
	if !result.FinishedAt.IsZero() {
		return r.queries.UpdateExecutionStatusAt(ctx, sqlc.UpdateExecutionStatusAtParams{
			ExecutionID: id,
			StatusAt:    toPgTimestamp(result.FinishedAt),
		})
	}

	return nil
}

// UpdateReport adds a report
func (r *PostgresRepository) UpdateReport(ctx context.Context, id string, report *testkube.TestWorkflowReport) error {
	summary, _ := toJSONB(report.Summary)
	return r.queries.UpdateTestWorkflowExecutionReport(ctx, sqlc.UpdateTestWorkflowExecutionReportParams{
		ExecutionID: id,
		Ref:         toPgText(report.Ref),
		Kind:        toPgText(report.Kind),
		File:        toPgText(report.File),
		Summary:     summary,
	})
}

// UpdateOutput replaces all outputs
func (r *PostgresRepository) UpdateOutput(ctx context.Context, id string, refs []testkube.TestWorkflowOutput) error {
	tx, err := r.db.Begin(ctx)
	if err != nil {
		return err
	}
	defer tx.Rollback(ctx)

	qtx := r.queries.WithTx(tx)

	// Delete existing outputs
	err = qtx.DeleteTestWorkflowOutputs(ctx, id)
	if err != nil {
		return err
	}

	// Insert new outputs
	err = r.insertOutputs(ctx, qtx, id, refs)
	if err != nil {
		return err
	}

	return tx.Commit(ctx)
}

// UpdateResourceAggregations updates resource aggregations
func (r *PostgresRepository) UpdateResourceAggregations(ctx context.Context, id string, resourceAggregations *testkube.TestWorkflowExecutionResourceAggregationsReport) error {
	global, _ := toJSONB(resourceAggregations.Global)
	step, _ := toJSONB(resourceAggregations.Step)

	return r.queries.UpdateTestWorkflowExecutionResourceAggregations(ctx, sqlc.UpdateTestWorkflowExecutionResourceAggregationsParams{
		ExecutionID: id,
		Global:      global,
		Step:        step,
	})
}

// DeleteByTestWorkflow deletes executions by workflow name
func (r *PostgresRepository) DeleteByTestWorkflow(ctx context.Context, workflowName string) error {
	if r.sequenceRepository != nil {
		err := r.sequenceRepository.DeleteExecutionNumber(ctx, workflowName, sequence.ExecutionTypeTestWorkflow)
		if err != nil {
			return err
		}
	}

	return r.queries.DeleteTestWorkflowExecutionsByTestWorkflow(ctx, workflowName)
}

// DeleteAll deletes all executions
func (r *PostgresRepository) DeleteAll(ctx context.Context) error {
	if r.sequenceRepository != nil {
		err := r.sequenceRepository.DeleteAllExecutionNumbers(ctx, sequence.ExecutionTypeTestWorkflow)
		if err != nil {
			return err
		}
	}

	return r.queries.DeleteAllTestWorkflowExecutions(ctx)
}

// DeleteByTestWorkflows deletes executions by workflow names
func (r *PostgresRepository) DeleteByTestWorkflows(ctx context.Context, workflowNames []string) error {
	if len(workflowNames) == 0 {
		return nil
	}

	if r.sequenceRepository != nil {
		err := r.sequenceRepository.DeleteExecutionNumbers(ctx, workflowNames, sequence.ExecutionTypeTestWorkflow)
		if err != nil {
			return err
		}
	}

	return r.queries.DeleteTestWorkflowExecutionsByTestWorkflows(ctx, workflowNames)
}

// GetNextExecutionNumber gets next execution number
func (r *PostgresRepository) GetNextExecutionNumber(ctx context.Context, name string) (int32, error) {
	if r.sequenceRepository == nil {
		return 0, errors.New("no sequence repository provided")
	}

	return r.sequenceRepository.GetNextExecutionNumber(ctx, name, sequence.ExecutionTypeTestWorkflow)
}

// GetTestWorkflowMetrics returns metrics
func (r *PostgresRepository) GetTestWorkflowMetrics(ctx context.Context, name string, limit, last int) (testkube.ExecutionsMetrics, error) {
	metrics := testkube.ExecutionsMetrics{}

	var la int32
	if last < 0 || last > math.MaxInt32 {
		la = 0
	} else {
		la = int32(last)
	}

	var li int32
	if limit < 0 || limit > math.MaxInt32 {
		li = 0
	} else {
		li = int32(limit)
	}

	rows, err := r.queries.GetTestWorkflowMetrics(ctx, sqlc.GetTestWorkflowMetricsParams{
		WorkflowName: toPgText(name),
		LastDays:     toPgInt4(la),
		Lmt:          int32(li),
	})
	if err != nil {
		return metrics, err
	}

	executions := make([]testkube.ExecutionsMetricsExecutions, len(rows))
	for i, row := range rows {
		executions[i] = testkube.ExecutionsMetricsExecutions{
			ExecutionId: row.ExecutionID,
			GroupId:     fromPgText(row.GroupID),
			Duration:    fromPgText(row.Duration),
			DurationMs:  fromPgInt4(row.DurationMs),
			Status:      fromPgText(row.Status),
			Name:        row.Name,
			StartTime:   fromPgTimestamp(row.StartTime),
			RunnerId:    fromPgText(row.RunnerID),
		}
	}

	metrics = common.CalculateMetrics(executions)
	if limit > 0 && limit < len(metrics.Executions) {
		metrics.Executions = metrics.Executions[:limit]
	}

	return metrics, nil
}

// GetPreviousFinishedState gets previous finished state
func (r *PostgresRepository) GetPreviousFinishedState(ctx context.Context, testWorkflowName string, date time.Time) (testkube.TestWorkflowStatus, error) {
	status, err := r.queries.GetPreviousFinishedState(ctx, sqlc.GetPreviousFinishedStateParams{
		WorkflowName: toPgText(testWorkflowName),
		Date:         toPgTimestamp(date),
	})
	if err != nil {
		if errors.Is(err, pgx.ErrNoRows) {
			return "", nil
		}
		return "", err
	}

	return testkube.TestWorkflowStatus(fromPgText(status)), nil
}

// GetExecutionTags returns execution tags
func (r *PostgresRepository) GetExecutionTags(ctx context.Context, testWorkflowName string) (map[string][]string, error) {
	rows, err := r.queries.GetTestWorkflowExecutionTags(ctx, testWorkflowName)
	if err != nil {
		return nil, err
	}

	tags := make(map[string][]string)
	for _, row := range rows {
		var values []string
		for _, val := range row.Values {
			values = append(values, val)
		}
		tags[row.TagKey] = values
	}

	return tags, nil
}

// Init initializes execution
func (r *PostgresRepository) Init(ctx context.Context, id string, data testworkflow.InitData) error {
	return r.queries.InitTestWorkflowExecution(ctx, sqlc.InitTestWorkflowExecutionParams{
		ID:        id,
		Namespace: toPgText(data.Namespace),
		RunnerID:  toPgText(data.RunnerID),
	})
}

// Assign assigns execution to runner
func (r *PostgresRepository) Assign(ctx context.Context, id string, prevRunnerId string, newRunnerId string, assignedAt *time.Time) (bool, error) {
	var assignedAtPg pgtype.Timestamptz
	if assignedAt != nil {
		assignedAtPg = toPgTimestamp(*assignedAt)
	}

	resultId, err := r.queries.AssignTestWorkflowExecution(ctx, sqlc.AssignTestWorkflowExecutionParams{
		ID:           id,
		PrevRunnerID: toPgText(prevRunnerId),
		NewRunnerID:  toPgText(newRunnerId),
		AssignedAt:   assignedAtPg,
	})
	if err != nil {
		if errors.Is(err, pgx.ErrNoRows) {
			return false, nil
		}
		return false, err
	}

	return resultId != "", nil
}

// GetUnassigned returns unassigned executions
func (r *PostgresRepository) GetUnassigned(ctx context.Context) ([]testkube.TestWorkflowExecution, error) {
	rows, err := r.queries.GetUnassignedTestWorkflowExecutions(ctx)
	if err != nil {
		return nil, err
	}

	result := make([]testkube.TestWorkflowExecution, len(rows))
	for i, row := range rows {
		execution := r.convertCompleteRowToExecution(row)
		result[i] = *execution.UnscapeDots()

		// Populate config params if resolved workflow exists
		if execution.ResolvedWorkflow != nil && execution.ResolvedWorkflow.Spec != nil {
			result[i].ConfigParams = populateConfigParams(execution.ResolvedWorkflow, result[i].ConfigParams)
		}
	}

	return result, nil
}

// AbortIfQueued aborts execution if queued
func (r *PostgresRepository) AbortIfQueued(ctx context.Context, id string) (bool, error) {
	ts := time.Now()

	tx, err := r.db.Begin(ctx)
	if err != nil {
		return false, err
	}
	defer tx.Rollback(ctx)

	qtx := r.queries.WithTx(tx)

	// Abort the execution
	resultId, err := qtx.AbortTestWorkflowExecutionIfQueued(ctx, sqlc.AbortTestWorkflowExecutionIfQueuedParams{
		ID:        id,
		AbortTime: toPgTimestamp(ts),
	})
	if err != nil {
		if errors.Is(err, pgx.ErrNoRows) {
			return false, nil
		}
		return false, err
	}

	if resultId == "" {
		return false, nil
	}

	// Abort the result
	err = qtx.AbortTestWorkflowResultIfQueued(ctx, sqlc.AbortTestWorkflowResultIfQueuedParams{
		ID:        id,
		AbortTime: toPgTimestamp(ts),
	})
	if err != nil {
		return false, err
	}

	err = tx.Commit(ctx)
	if err != nil {
		return false, err
	}

	return true, nil
}

// Helper functions for building query parameters and converting rows
// These would need to be implemented based on the specific filter structure
func (r *PostgresRepository) buildTotalsParams(filter testworkflow.Filter) sqlc.GetTestWorkflowExecutionsTotalsParams {
	params := sqlc.GetTestWorkflowExecutionsTotalsParams{}

	if filter.NameDefined() {
		params.WorkflowName = toPgText(filter.Name())
	}

	if filter.NamesDefined() {
		names := filter.Names()
		pgNames := make([]pgtype.Text, len(names))
		for i, name := range names {
			pgNames[i] = toPgText(name)
		}
		params.WorkflowNames = pgNames
	}

	if filter.TextSearchDefined() {
		params.TextSearch = toPgText(filter.TextSearch())
	}

	if filter.StartDateDefined() {
		params.StartDate = toPgTimestamp(filter.StartDate())
	}

	if filter.EndDateDefined() {
		params.EndDate = toPgTimestamp(filter.EndDate())
	}

	if filter.LastNDaysDefined() {
		params.LastNDays = toPgInt4(int32(filter.LastNDays()))
	}

	if filter.StatusesDefined() {
		statuses := filter.Statuses()
		pgStatuses := make([]pgtype.Text, len(statuses))
		for i, status := range statuses {
			pgStatuses[i] = toPgText(string(status))
		}
		params.Statuses = pgStatuses
	}

	if filter.RunnerIDDefined() {
		params.RunnerID = toPgText(filter.RunnerID())
	}

	if filter.AssignedDefined() {
		params.Assigned = toPgBool(filter.Assigned())
	}

	if filter.ActorNameDefined() {
		params.ActorName = toPgText(filter.ActorName())
	}

	if filter.ActorTypeDefined() {
		params.ActorType = toPgText(string(filter.ActorType()))
	}

	if filter.GroupIDDefined() {
		params.GroupID = toPgText(filter.GroupID())
	}

	if filter.InitializedDefined() {
		params.Initialized = toPgBool(filter.Initialized())
	}

	return params
}

func (r *PostgresRepository) buildExecutionParams(filter testworkflow.Filter) sqlc.GetTestWorkflowExecutionsParams {
	params := sqlc.GetTestWorkflowExecutionsParams{
		Fst: int32(filter.Page() * filter.PageSize()),
		Lmt: int32(filter.PageSize()),
	}

	if filter.NameDefined() {
		params.WorkflowName = toPgText(filter.Name())
	}

	if filter.NamesDefined() {
		names := filter.Names()
		pgNames := make([]pgtype.Text, len(names))
		for i, name := range names {
			pgNames[i] = toPgText(name)
		}
		params.WorkflowNames = pgNames
	}

	if filter.TextSearchDefined() {
		params.TextSearch = toPgText(filter.TextSearch())
	}

	if filter.StartDateDefined() {
		params.StartDate = toPgTimestamp(filter.StartDate())
	}

	if filter.EndDateDefined() {
		params.EndDate = toPgTimestamp(filter.EndDate())
	}

	if filter.LastNDaysDefined() {
		params.LastNDays = toPgInt4(int32(filter.LastNDays()))
	}

	if filter.StatusesDefined() {
		statuses := filter.Statuses()
		pgStatuses := make([]pgtype.Text, len(statuses))
		for i, status := range statuses {
			pgStatuses[i] = toPgText(string(status))
		}
		params.Statuses = pgStatuses
	}

	if filter.RunnerIDDefined() {
		params.RunnerID = toPgText(filter.RunnerID())
	}

	if filter.AssignedDefined() {
		params.Assigned = toPgBool(filter.Assigned())
	}

	if filter.ActorNameDefined() {
		params.ActorName = toPgText(filter.ActorName())
	}

	if filter.ActorTypeDefined() {
		params.ActorType = toPgText(string(filter.ActorType()))
	}

	if filter.GroupIDDefined() {
		params.GroupID = toPgText(filter.GroupID())
	}

	if filter.InitializedDefined() {
		params.Initialized = toPgBool(filter.Initialized())
	}

	return params
}

func (r *PostgresRepository) buildFinishedExecutionParams(filter testworkflow.Filter) sqlc.GetFinishedTestWorkflowExecutionsParams {
	params := sqlc.GetFinishedTestWorkflowExecutionsParams{
		Fst: int32(filter.Page() * filter.PageSize()),
		Lmt: int32(filter.PageSize()),
	}

	if filter.NameDefined() {
		params.WorkflowName = toPgText(filter.Name())
	}

	if filter.NamesDefined() {
		names := filter.Names()
		pgNames := make([]pgtype.Text, len(names))
		for i, name := range names {
			pgNames[i] = toPgText(name)
		}
		params.WorkflowNames = pgNames
	}

	if filter.TextSearchDefined() {
		params.TextSearch = toPgText(filter.TextSearch())
	}

	if filter.StartDateDefined() {
		params.StartDate = toPgTimestamp(filter.StartDate())
	}

	if filter.EndDateDefined() {
		params.EndDate = toPgTimestamp(filter.EndDate())
	}

	if filter.LastNDaysDefined() {
		params.LastNDays = toPgInt4(int32(filter.LastNDays()))
	}

	if filter.StatusesDefined() {
		statuses := filter.Statuses()
		pgStatuses := make([]pgtype.Text, len(statuses))
		for i, status := range statuses {
			pgStatuses[i] = toPgText(string(status))
		}
		params.Statuses = pgStatuses
	}

	if filter.RunnerIDDefined() {
		params.RunnerID = toPgText(filter.RunnerID())
	}

	if filter.AssignedDefined() {
		params.Assigned = toPgBool(filter.Assigned())
	}

	if filter.ActorNameDefined() {
		params.ActorName = toPgText(filter.ActorName())
	}

	if filter.ActorTypeDefined() {
		params.ActorType = toPgText(string(filter.ActorType()))
	}

	if filter.GroupIDDefined() {
		params.GroupID = toPgText(filter.GroupID())
	}

	if filter.InitializedDefined() {
		params.Initialized = toPgBool(filter.Initialized())
	}

	return params
}

// Update the buildSummaryParams method to use the same complete query
func (r *PostgresRepository) buildSummaryParams(filter Filter) sqlc.GetTestWorkflowExecutionsSummaryParams {
	params := sqlc.GetTestWorkflowExecutionsSummaryParams{
		Fst: int32(filter.Page() * filter.PageSize()),
		Lmt: int32(filter.PageSize()),
	}

	if filter.NameDefined() {
		params.WorkflowName = toPgText(filter.Name())
	}

	if filter.NamesDefined() {
		names := filter.Names()
		pgNames := make([]pgtype.Text, len(names))
		for i, name := range names {
			pgNames[i] = toPgText(name)
		}
		params.WorkflowNames = pgNames
	}

	if filter.TextSearchDefined() {
		params.TextSearch = toPgText(filter.TextSearch())
	}

	if filter.StartDateDefined() {
		params.StartDate = toPgTimestamp(filter.StartDate())
	}

	if filter.EndDateDefined() {
		params.EndDate = toPgTimestamp(filter.EndDate())
	}

	if filter.LastNDaysDefined() {
		params.LastNDays = toPgInt4(int32(filter.LastNDays()))
	}

	if filter.StatusesDefined() {
		statuses := filter.Statuses()
		pgStatuses := make([]pgtype.Text, len(statuses))
		for i, status := range statuses {
			pgStatuses[i] = toPgText(string(status))
		}
		params.Statuses = pgStatuses
	}

	if filter.RunnerIDDefined() {
		params.RunnerID = toPgText(filter.RunnerID())
	}

	if filter.AssignedDefined() {
		params.Assigned = toPgBool(filter.Assigned())
	}

	if filter.ActorNameDefined() {
		params.ActorName = toPgText(filter.ActorName())
	}

	if filter.ActorTypeDefined() {
		params.ActorType = toPgText(string(filter.ActorType()))
	}

	if filter.GroupIDDefined() {
		params.GroupID = toPgText(filter.GroupID())
	}

	if filter.InitializedDefined() {
		params.Initialized = toPgBool(filter.Initialized())
	}

	return params
}

// Helper methods for building complex objects

func (r *PostgresRepository) parseExecutionJSONFields(execution *testkube.TestWorkflowExecution, runnerTarget, runnerOriginalTarget, tags, runningContext, configParams []byte) {
	if len(runnerTarget) > 0 {
		execution.RunnerTarget, _ = fromJSONB[testkube.ExecutionTarget](runnerTarget)
	}

	if len(runnerOriginalTarget) > 0 {
		execution.RunnerOriginalTarget, _ = fromJSONB[testkube.ExecutionTarget](runnerOriginalTarget)
	}

	if len(tags) > 0 {
		json.Unmarshal(tags, &execution.Tags)
	}

	if len(runningContext) > 0 {
		execution.RunningContext, _ = fromJSONB[testkube.TestWorkflowRunningContext](runningContext)
	}

	if len(configParams) > 0 {
		json.Unmarshal(configParams, &execution.ConfigParams)
	}
}

func (r *PostgresRepository) buildResultFromRow(
	status, predictedStatus pgtype.Text,
	queuedAt, startedAt, finishedAt pgtype.Timestamptz,
	duration, totalDuration pgtype.Text,
	durationMs, pausedMs, totalDurationMs pgtype.Int4,
	pauses, initialization, steps []byte,
) *testkube.TestWorkflowResult {
	result := &testkube.TestWorkflowResult{
		QueuedAt:        fromPgTimestamp(queuedAt),
		StartedAt:       fromPgTimestamp(startedAt),
		FinishedAt:      fromPgTimestamp(finishedAt),
		Duration:        fromPgText(duration),
		TotalDuration:   fromPgText(totalDuration),
		DurationMs:      fromPgInt4(durationMs),
		PausedMs:        fromPgInt4(pausedMs),
		TotalDurationMs: fromPgInt4(totalDurationMs),
	}

	if status.Valid {
		s := testkube.TestWorkflowStatus(status.String)
		result.Status = &s
	}

	if predictedStatus.Valid {
		ps := testkube.TestWorkflowStatus(predictedStatus.String)
		result.PredictedStatus = &ps
	}

	if len(pauses) > 0 {
		json.Unmarshal(pauses, &result.Pauses)
	}

	if len(initialization) > 0 {
		result.Initialization, _ = fromJSONB[testkube.TestWorkflowStepResult](initialization)
	}

	if len(steps) > 0 {
		json.Unmarshal(steps, &result.Steps)
	}

	return result
}

func (r *PostgresRepository) buildResultFromRowSimple(
	status, predictedStatus pgtype.Text,
	queuedAt, startedAt, finishedAt pgtype.Timestamptz,
	duration, totalDuration pgtype.Text,
	durationMs, pausedMs, totalDurationMs pgtype.Int4,
) *testkube.TestWorkflowResult {
	result := &testkube.TestWorkflowResult{
		QueuedAt:        fromPgTimestamp(queuedAt),
		StartedAt:       fromPgTimestamp(startedAt),
		FinishedAt:      fromPgTimestamp(finishedAt),
		Duration:        fromPgText(duration),
		TotalDuration:   fromPgText(totalDuration),
		DurationMs:      fromPgInt4(durationMs),
		PausedMs:        fromPgInt4(pausedMs),
		TotalDurationMs: fromPgInt4(totalDurationMs),
	}

	if status.Valid {
		s := testkube.TestWorkflowStatus(status.String)
		result.Status = &s
	}

	if predictedStatus.Valid {
		ps := testkube.TestWorkflowStatus(predictedStatus.String)
		result.PredictedStatus = &ps
	}

	return result
}

func (r *PostgresRepository) buildResultSummaryFromRowSimple(
	status, predictedStatus pgtype.Text,
	queuedAt, startedAt, finishedAt pgtype.Timestamptz,
	duration, totalDuration pgtype.Text,
	durationMs, pausedMs, totalDurationMs pgtype.Int4,
) *testkube.TestWorkflowResultSummary {
	result := &testkube.TestWorkflowResultSummary{
		QueuedAt:        fromPgTimestamp(queuedAt),
		StartedAt:       fromPgTimestamp(startedAt),
		FinishedAt:      fromPgTimestamp(finishedAt),
		Duration:        fromPgText(duration),
		TotalDuration:   fromPgText(totalDuration),
		DurationMs:      fromPgInt4(durationMs),
		PausedMs:        fromPgInt4(pausedMs),
		TotalDurationMs: fromPgInt4(totalDurationMs),
	}

	if status.Valid {
		s := testkube.TestWorkflowStatus(status.String)
		result.Status = &s
	}

	if predictedStatus.Valid {
		ps := testkube.TestWorkflowStatus(predictedStatus.String)
		result.PredictedStatus = &ps
	}

	return result
}

func (r *PostgresRepository) buildWorkflowFromRow(
	name, namespace, description pgtype.Text,
	labels, annotations []byte,
	created, updated pgtype.Timestamptz,
	spec []byte,
	readOnly pgtype.Bool,
	status []byte,
) *testkube.TestWorkflow {
	workflow := &testkube.TestWorkflow{
		Name:        fromPgText(name),
		Namespace:   fromPgText(namespace),
		Description: fromPgText(description),
		Created:     fromPgTimestamp(created),
		Updated:     fromPgTimestamp(updated),
		ReadOnly:    fromPgBool(readOnly),
	}

	if len(labels) > 0 {
		json.Unmarshal(labels, &workflow.Labels)
	}

	if len(annotations) > 0 {
		json.Unmarshal(annotations, &workflow.Annotations)
	}

	if len(spec) > 0 {
		workflow.Spec, _ = fromJSONB[testkube.TestWorkflowSpec](spec)
	}

	if len(status) > 0 {
		workflow.Status, _ = fromJSONB[testkube.TestWorkflowStatusSummary](status)
	}

	return workflow
}

func (r *PostgresRepository) updateMainExecution(ctx context.Context, qtx sqlc.TestWorkflowExecutionQueriesInterface, execution *testkube.TestWorkflowExecution) error {
	runnerTarget, _ := toJSONB(execution.RunnerTarget)
	runnerOriginalTarget, _ := toJSONB(execution.RunnerOriginalTarget)
	tags, _ := toJSONB(execution.Tags)
	runningContext, _ := toJSONB(execution.RunningContext)
	configParams, _ := toJSONB(execution.ConfigParams)

	// Placeholder - you would call the generated method here:
	return qtx.UpdateTestWorkflowExecution(ctx, sqlc.UpdateTestWorkflowExecutionParams{
		GroupID:                   toPgText(execution.GroupId),
		RunnerID:                  toPgText(execution.RunnerId),
		RunnerTarget:              runnerTarget,
		RunnerOriginalTarget:      runnerOriginalTarget,
		Name:                      execution.Name,
		Namespace:                 toPgText(execution.Namespace),
		Number:                    toPgInt4(execution.Number),
		ScheduledAt:               toPgTimestamp(execution.ScheduledAt),
		AssignedAt:                toPgTimestamp(execution.AssignedAt),
		StatusAt:                  toPgTimestamp(execution.StatusAt),
		TestWorkflowExecutionName: toPgText(execution.TestWorkflowExecutionName),
		DisableWebhooks:           toPgBool(execution.DisableWebhooks),
		Tags:                      tags,
		RunningContext:            runningContext,
		ConfigParams:              configParams,
		ID:                        execution.Id,
	})
}

// populateConfigParams - same as in mongo repository
func populateConfigParams(resolvedWorkflow *testkube.TestWorkflow, configParams map[string]testkube.TestWorkflowExecutionConfigValue) map[string]testkube.TestWorkflowExecutionConfigValue {
	if configParams == nil {
		configParams = make(map[string]testkube.TestWorkflowExecutionConfigValue)
	}

	for k, v := range resolvedWorkflow.Spec.Config {
		if v.Sensitive {
			configParams[k] = testkube.TestWorkflowExecutionConfigValue{
				Sensitive:         true,
				EmptyValue:        true,
				EmptyDefaultValue: true,
			}
			continue
		}

		if _, ok := configParams[k]; !ok {
			configParams[k] = testkube.TestWorkflowExecutionConfigValue{
				EmptyValue: true,
			}
		}

		data := configParams[k]
		if len(data.Value) > configParamSizeLimit {
			data.Value = data.Value[:configParamSizeLimit]
			data.Truncated = true
		}

		if v.Default_ != nil {
			data.DefaultValue = v.Default_.Value
		} else {
			data.EmptyDefaultValue = true
		}

		configParams[k] = data
	}

	return configParams
}

// Additional helper functions for tag processing
/*
func (r *PostgresRepository) buildTagSelector(tagSelector string) string {
	if tagSelector == "" {
		return ""
	}

	items := strings.Split(tagSelector, ",")
	var conditions []string

	for _, item := range items {
		elements := strings.Split(item, "=")
		if len(elements) == 2 {
			// Tag with specific value
			conditions = append(conditions, fmt.Sprintf("tags->>'%s' = '%s'", utils.EscapeDots(elements[0]), elements[1]))
		} else if len(elements) == 1 {
			// Tag exists
			conditions = append(conditions, fmt.Sprintf("tags ? '%s'", utils.EscapeDots(elements[0])))
		}
	}

	if len(conditions) > 0 {
		return "(" + strings.Join(conditions, " AND ") + ")"
	}
	return ""
}

func (r *PostgresRepository) buildLabelSelector(labelSelector *LabelSelector) string {
	if labelSelector == nil || len(labelSelector.Or) == 0 {
		return ""
	}

	var conditions []string
	for _, label := range labelSelector.Or {
		if label.Value != nil {
			conditions = append(conditions, fmt.Sprintf("workflow.labels->>'%s' = '%s'", utils.EscapeDots(label.Key), *label.Value))
		} else if label.Exists != nil {
			if *label.Exists {
				conditions = append(conditions, fmt.Sprintf("workflow.labels ? '%s'", utils.EscapeDots(label.Key)))
			} else {
				conditions = append(conditions, fmt.Sprintf("NOT (workflow.labels ? '%s')", utils.EscapeDots(label.Key)))
			}
		}
	}

	if len(conditions) > 0 {
		return "(" + strings.Join(conditions, " OR ") + ")"
	}
	return ""
}

// Selector-related structures (if not already defined)
type LabelSelector struct {
	Or []LabelSelectorItem `json:"or,omitempty"`
}

type LabelSelectorItem struct {
	Key    string  `json:"key"`
	Value  *string `json:"value,omitempty"`
	Exists *bool   `json:"exists,omitempty"`
}
*/
